{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('DisasterResponse', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['related'] = df['related'].replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'genre', 'original'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.drop('child_alone', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize andremove stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RF ###\n",
    "##########\n",
    "\n",
    "clf_rf = Pipeline([\n",
    "    ('countvec', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidftrans', TfidfTransformer()),\n",
    "    ('multiclf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        #y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nbsvm = Pipeline([\n",
    "    ('countvec', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidftrans', TfidfTransformer()),\n",
    "    ('multiclf', MultiOutputClassifier(NbSvmClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20972,), (5244,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "CPU times: user 3min 10s, sys: 7.38 s, total: 3min 18s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Model: Random Forest')\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NB-SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 24.2 s, total: 2min 38s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Model: NB-SVM')\n",
    "clf_nbsvm.fit(X_train, y_train)\n",
    "y_pred_nbsvm = clf_nbsvm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.91      0.87      3978\n",
      "               request       0.79      0.42      0.54       895\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.75      0.61      0.67      2131\n",
      "          medical_help       0.58      0.10      0.17       422\n",
      "      medical_products       0.66      0.11      0.20       270\n",
      "     search_and_rescue       0.64      0.07      0.13       127\n",
      "              security       0.67      0.02      0.04        88\n",
      "              military       0.59      0.11      0.18       155\n",
      "                 water       0.84      0.33      0.47       339\n",
      "                  food       0.84      0.42      0.56       595\n",
      "               shelter       0.82      0.36      0.50       470\n",
      "              clothing       0.73      0.11      0.19        73\n",
      "                 money       0.83      0.10      0.17       104\n",
      "        missing_people       0.00      0.00      0.00        60\n",
      "              refugees       0.65      0.06      0.12       171\n",
      "                 death       0.81      0.14      0.24       237\n",
      "             other_aid       0.37      0.04      0.07       695\n",
      "infrastructure_related       0.17      0.00      0.01       328\n",
      "             transport       0.69      0.09      0.16       240\n",
      "             buildings       0.82      0.10      0.18       267\n",
      "           electricity       1.00      0.01      0.02       122\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.00      0.00      0.00        46\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.00      0.00      0.00        67\n",
      "  other_infrastructure       0.00      0.00      0.00       223\n",
      "       weather_related       0.82      0.62      0.70      1438\n",
      "                floods       0.87      0.36      0.51       411\n",
      "                 storm       0.75      0.43      0.54       486\n",
      "                  fire       0.50      0.04      0.07        53\n",
      "            earthquake       0.88      0.77      0.82       478\n",
      "                  cold       0.72      0.11      0.19       117\n",
      "         other_weather       0.57      0.04      0.08       276\n",
      "         direct_report       0.71      0.32      0.44      1021\n",
      "\n",
      "           avg / total       0.73      0.49      0.54     16463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Model: Random Forest')\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                            target_names = y_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NB-SVM\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.95      0.89      3978\n",
      "               request       0.82      0.54      0.65       895\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.78      0.64      0.71      2131\n",
      "          medical_help       0.64      0.24      0.35       422\n",
      "      medical_products       0.71      0.28      0.40       270\n",
      "     search_and_rescue       0.76      0.15      0.25       127\n",
      "              security       0.50      0.02      0.04        88\n",
      "              military       0.54      0.26      0.35       155\n",
      "                 water       0.78      0.54      0.64       339\n",
      "                  food       0.85      0.65      0.74       595\n",
      "               shelter       0.80      0.53      0.63       470\n",
      "              clothing       0.72      0.32      0.44        73\n",
      "                 money       0.54      0.24      0.33       104\n",
      "        missing_people       0.71      0.08      0.15        60\n",
      "              refugees       0.70      0.27      0.39       171\n",
      "                 death       0.84      0.46      0.60       237\n",
      "             other_aid       0.51      0.09      0.15       695\n",
      "infrastructure_related       0.47      0.04      0.08       328\n",
      "             transport       0.75      0.15      0.25       240\n",
      "             buildings       0.78      0.27      0.41       267\n",
      "           electricity       0.74      0.20      0.32       122\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.40      0.04      0.08        46\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.67      0.03      0.06        67\n",
      "  other_infrastructure       0.47      0.03      0.06       223\n",
      "       weather_related       0.85      0.69      0.76      1438\n",
      "                floods       0.90      0.57      0.70       411\n",
      "                 storm       0.71      0.53      0.61       486\n",
      "                  fire       0.71      0.23      0.34        53\n",
      "            earthquake       0.88      0.76      0.81       478\n",
      "                  cold       0.76      0.32      0.45       117\n",
      "         other_weather       0.62      0.13      0.21       276\n",
      "         direct_report       0.73      0.40      0.52      1021\n",
      "\n",
      "             micro avg       0.80      0.58      0.67     16463\n",
      "             macro avg       0.64      0.30      0.38     16463\n",
      "          weighted avg       0.76      0.58      0.63     16463\n",
      "           samples avg       0.65      0.51      0.52     16463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Model: NB-SVM')\n",
    "print(classification_report(y_test, y_pred_nbsvm, \n",
    "                               target_names = y_test.columns,\n",
    "                               output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(y_test, y_pred, metric):\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    weighted_avg = report['weighted avg']\n",
    "    return weighted_avg[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(scorer, metric='f1-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  NBSVM  ##\n",
    "#############\n",
    "\n",
    "clf_nbsvm = Pipeline([\n",
    "        ('countvec', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(NbSvmClassifier())),\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__C': [1.0, 5.0, 10.0],\n",
    "    'countvec__ngram_range': [(1, 1), (1, 2)]     \n",
    "}\n",
    "\n",
    "# optimize model\n",
    "nbsvm_grid = GridSearchCV(clf_nbsvm, parameters, scoring=f1_scorer, cv=3, verbose=10, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed: 31.8min finished\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        s...tiOutputClassifier(estimator=NbSvmClassifier(C=1.0, dual=False, n_jobs=1),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'clf__estimator__C': [1.0, 5.0, 10.0], 'countvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(scorer, metric=f1-score), verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbsvm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__C': 10.0, 'countvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbsvm_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.88      3978\n",
      "               request       0.80      0.58      0.67       895\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.74      0.72      0.73      2131\n",
      "          medical_help       0.61      0.32      0.42       422\n",
      "      medical_products       0.70      0.32      0.44       270\n",
      "     search_and_rescue       0.71      0.17      0.28       127\n",
      "              security       0.40      0.02      0.04        88\n",
      "              military       0.54      0.34      0.42       155\n",
      "                 water       0.73      0.63      0.68       339\n",
      "                  food       0.83      0.72      0.77       595\n",
      "               shelter       0.77      0.59      0.67       470\n",
      "              clothing       0.78      0.44      0.56        73\n",
      "                 money       0.51      0.24      0.33       104\n",
      "        missing_people       1.00      0.15      0.26        60\n",
      "              refugees       0.63      0.30      0.41       171\n",
      "                 death       0.80      0.49      0.60       237\n",
      "             other_aid       0.51      0.14      0.22       695\n",
      "infrastructure_related       0.42      0.06      0.11       328\n",
      "             transport       0.63      0.22      0.32       240\n",
      "             buildings       0.75      0.39      0.51       267\n",
      "           electricity       0.63      0.27      0.38       122\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.25      0.04      0.07        46\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.50      0.01      0.03        67\n",
      "  other_infrastructure       0.22      0.02      0.03       223\n",
      "       weather_related       0.82      0.76      0.79      1438\n",
      "                floods       0.86      0.59      0.70       411\n",
      "                 storm       0.70      0.64      0.67       486\n",
      "                  fire       0.65      0.25      0.36        53\n",
      "            earthquake       0.86      0.72      0.78       478\n",
      "                  cold       0.69      0.34      0.46       117\n",
      "         other_weather       0.57      0.17      0.26       276\n",
      "         direct_report       0.70      0.46      0.55      1021\n",
      "\n",
      "             micro avg       0.78      0.62      0.69     16463\n",
      "             macro avg       0.60      0.34      0.41     16463\n",
      "          weighted avg       0.74      0.62      0.65     16463\n",
      "           samples avg       0.63      0.53      0.53     16463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = nbsvm_grid.best_estimator_\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(y_test, preds, target_names = y_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request has 21742 0's and 4474 1's\n",
      "offer has 26098 0's and 118 1's\n",
      "medical_help has 24132 0's and 2084 1's\n",
      "medical_products has 24903 0's and 1313 1's\n",
      "search_and_rescue has 25492 0's and 724 1's\n",
      "security has 25745 0's and 471 1's\n",
      "military has 25356 0's and 860 1's\n",
      "water has 24544 0's and 1672 1's\n",
      "food has 23293 0's and 2923 1's\n",
      "shelter has 23902 0's and 2314 1's\n",
      "clothing has 25811 0's and 405 1's\n",
      "money has 25612 0's and 604 1's\n",
      "missing_people has 25918 0's and 298 1's\n",
      "refugees has 25341 0's and 875 1's\n",
      "death has 25022 0's and 1194 1's\n",
      "other_aid has 22770 0's and 3446 1's\n",
      "infrastructure_related has 24511 0's and 1705 1's\n",
      "transport has 25015 0's and 1201 1's\n",
      "buildings has 24883 0's and 1333 1's\n",
      "electricity has 25684 0's and 532 1's\n",
      "tools has 26057 0's and 159 1's\n",
      "hospitals has 25933 0's and 283 1's\n",
      "shops has 26096 0's and 120 1's\n",
      "aid_centers has 25907 0's and 309 1's\n",
      "other_infrastructure has 25065 0's and 1151 1's\n",
      "floods has 24061 0's and 2155 1's\n",
      "storm has 23773 0's and 2443 1's\n",
      "fire has 25934 0's and 282 1's\n",
      "earthquake has 23761 0's and 2455 1's\n",
      "cold has 25686 0's and 530 1's\n",
      "other_weather has 24840 0's and 1376 1's\n",
      "direct_report has 21141 0's and 5075 1's\n"
     ]
    }
   ],
   "source": [
    "for col in Y.columns:\n",
    "    n0, n1 = Y[col].value_counts()[0], Y[col].value_counts()[1]\n",
    "    if n0/n1 > 4:\n",
    "        print(f\"{col} has {n0} 0's and {n1} 1's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF\n",
    "* other embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "class FasterCountTag(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    SpaCy NER Tagger. \n",
    "    '''\n",
    "    def __init__(self, tag=['EVENT', 'LOC']):\n",
    "        # Tag ref: https://spacy.io/api/annotation#named-entities\n",
    "        self.tag = tag\n",
    "        \n",
    "        \n",
    "    def count_tag(self, text):\n",
    "        doc = nlp(text)\n",
    "        counts = 0\n",
    "        \n",
    "        for X in doc.ents:\n",
    "            if X.label_ in self.tag:\n",
    "                counts += 1\n",
    "                \n",
    "        return counts\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.count_tag)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['EVENT', 'LOC', 'GPE', 'MONEY', 'ORG']\n",
    "tag = ['EVENT', 'LOC']\n",
    "\n",
    "clf_nbsvm = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "\n",
    "        ('NERTagger', FasterCountTag(tag=tag))\n",
    "    ])),\n",
    "\n",
    "    ('clf', MultiOutputClassifier(NbSvmClassifier(C=10.0)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NB-SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 6s, sys: 25.6 s, total: 10min 31s\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Model: NB-SVM')\n",
    "clf_nbsvm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.89      3978\n",
      "               request       0.80      0.58      0.67       895\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.74      0.72      0.73      2131\n",
      "          medical_help       0.60      0.32      0.42       422\n",
      "      medical_products       0.70      0.32      0.44       270\n",
      "     search_and_rescue       0.71      0.17      0.28       127\n",
      "              security       0.40      0.02      0.04        88\n",
      "              military       0.54      0.34      0.41       155\n",
      "                 water       0.74      0.63      0.68       339\n",
      "                  food       0.83      0.72      0.77       595\n",
      "               shelter       0.78      0.59      0.67       470\n",
      "              clothing       0.78      0.44      0.56        73\n",
      "                 money       0.51      0.24      0.33       104\n",
      "        missing_people       1.00      0.15      0.26        60\n",
      "              refugees       0.62      0.29      0.40       171\n",
      "                 death       0.79      0.49      0.61       237\n",
      "             other_aid       0.52      0.14      0.22       695\n",
      "infrastructure_related       0.42      0.06      0.11       328\n",
      "             transport       0.63      0.22      0.32       240\n",
      "             buildings       0.75      0.40      0.52       267\n",
      "           electricity       0.64      0.28      0.39       122\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.25      0.04      0.07        46\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.50      0.01      0.03        67\n",
      "  other_infrastructure       0.22      0.02      0.03       223\n",
      "       weather_related       0.82      0.76      0.79      1438\n",
      "                floods       0.86      0.59      0.70       411\n",
      "                 storm       0.69      0.63      0.66       486\n",
      "                  fire       0.65      0.25      0.36        53\n",
      "            earthquake       0.86      0.72      0.78       478\n",
      "                  cold       0.69      0.34      0.46       117\n",
      "         other_weather       0.60      0.17      0.27       276\n",
      "         direct_report       0.70      0.46      0.55      1021\n",
      "\n",
      "             micro avg       0.78      0.62      0.69     16463\n",
      "             macro avg       0.60      0.34      0.41     16463\n",
      "          weighted avg       0.74      0.62      0.65     16463\n",
      "           samples avg       0.63      0.53      0.53     16463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "new_preds = clf_nbsvm.predict(X_test)\n",
    "print(classification_report(y_test, new_preds, \n",
    "                            target_names = y_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open(model_filepath, 'wb') as file:\n",
    "#         pickle.dump(model, file)\n",
    "#     except IOError as e:\n",
    "#         print(\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "#     except:\n",
    "#         print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(model, open('final_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NB-SVM\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.95      0.89      3978\n",
      "               request       0.82      0.54      0.65       895\n",
      "                 offer       0.00      0.00      0.00        26\n",
      "           aid_related       0.78      0.64      0.70      2131\n",
      "          medical_help       0.65      0.24      0.35       422\n",
      "      medical_products       0.72      0.29      0.42       270\n",
      "     search_and_rescue       0.76      0.15      0.25       127\n",
      "              security       0.50      0.02      0.04        88\n",
      "              military       0.53      0.27      0.36       155\n",
      "                 water       0.78      0.56      0.65       339\n",
      "                  food       0.85      0.66      0.74       595\n",
      "               shelter       0.80      0.53      0.63       470\n",
      "              clothing       0.77      0.33      0.46        73\n",
      "                 money       0.54      0.26      0.35       104\n",
      "        missing_people       0.71      0.08      0.15        60\n",
      "              refugees       0.71      0.28      0.40       171\n",
      "                 death       0.82      0.47      0.60       237\n",
      "             other_aid       0.51      0.09      0.15       695\n",
      "infrastructure_related       0.48      0.05      0.08       328\n",
      "             transport       0.73      0.15      0.25       240\n",
      "             buildings       0.78      0.29      0.43       267\n",
      "           electricity       0.72      0.21      0.33       122\n",
      "                 tools       0.00      0.00      0.00        32\n",
      "             hospitals       0.40      0.04      0.08        46\n",
      "                 shops       0.00      0.00      0.00        22\n",
      "           aid_centers       0.67      0.03      0.06        67\n",
      "  other_infrastructure       0.46      0.03      0.05       223\n",
      "       weather_related       0.85      0.70      0.77      1438\n",
      "                floods       0.89      0.57      0.70       411\n",
      "                 storm       0.71      0.54      0.62       486\n",
      "                  fire       0.69      0.21      0.32        53\n",
      "            earthquake       0.88      0.76      0.81       478\n",
      "                  cold       0.77      0.32      0.45       117\n",
      "         other_weather       0.59      0.12      0.19       276\n",
      "         direct_report       0.73      0.40      0.52      1021\n",
      "\n",
      "           avg / total       0.76      0.58      0.63     16463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieunguyen/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open('final_model.sav', 'rb'))\n",
    "# preds = loaded_model.predict(X_test)\n",
    "\n",
    "# print(classification_report(y_test, preds, \n",
    "#                             target_names = y_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n",
    "\n",
    "y_train = y_train.values\n",
    "\n",
    "\n",
    "max_features = 30000\n",
    "maxlen = 100\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "        \n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc], verbose=2)\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test, batch_size=1024)\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
